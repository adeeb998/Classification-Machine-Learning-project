{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee9da195",
   "metadata": {},
   "source": [
    "# Final Classification Project\n",
    "**Bank Marketing (UCI) â€” Auto-download + Full ML pipeline**\n",
    "\n",
    "Run each cell in order (Shift+Enter). This notebook will:\n",
    "- Download dataset automatically if not present\n",
    "- Clean and preprocess data (handle 'unknown' as missing)\n",
    "- Encode categorical features and scale numeric features\n",
    "- Train Logistic Regression and Random Forest\n",
    "- Show accuracy, classification report, confusion matrix, and ROC curve\n",
    "- Save the trained Random Forest pipeline to disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b69cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (runs only if packages not available)\n",
    "import sys, subprocess, pkgutil\n",
    "required = ['pandas','numpy','scikit-learn','matplotlib','seaborn','joblib','wget']\n",
    "to_install = [p for p in required if not pkgutil.find_loader(p)]\n",
    "if to_install:\n",
    "    print(\"Installing:\", to_install)\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *to_install])\n",
    "else:\n",
    "    print(\"All required packages are already installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090729a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "import wget\n",
    "print('Imports done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805a40d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset automatically if not already present in the notebook directory\n",
    "data_filename = 'bank-full.csv'\n",
    "if not os.path.exists(data_filename):\n",
    "    print(\"Dataset not found locally. Downloading...\")\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip\"\n",
    "    zipname = \"bank.zip\"\n",
    "    try:\n",
    "        wget.download(url, zipname)\n",
    "        print(\"\\nDownloaded\", zipname)\n",
    "    except Exception as e:\n",
    "        print(\"wget failed:\", e)\n",
    "        # fallback to curl\n",
    "        try:\n",
    "            os.system(f\"curl -O {url}\")\n",
    "        except Exception as e2:\n",
    "            print(\"curl failed:\", e2)\n",
    "    # unzip\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(zipname, 'r') as z:\n",
    "        z.extractall()\n",
    "    print(\"Extracted files. You should now have 'bank-full.csv' in the current folder.\")\n",
    "else:\n",
    "    print(\"Dataset already present:\", data_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b065ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (semicolon separated)\n",
    "data = pd.read_csv(\"bank-full.csv\", sep=';')\n",
    "print(\"Loaded data shape:\", data.shape)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d897e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick info & distribution of target\n",
    "display(data.info())\n",
    "display(data.describe(include='all').T)\n",
    "print(\"\\nTarget value counts (y):\")\n",
    "print(data['y'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat 'unknown' as missing\n",
    "data = data.replace('unknown', np.nan)\n",
    "print('Missing value counts (first 20 cols):')\n",
    "print(data.isnull().sum().sort_values(ascending=False).head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4eaace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "target = 'y'\n",
    "data[target] = data[target].map({'yes':1, 'no':0})\n",
    "\n",
    "X = data.drop(columns=[target])\n",
    "y = data[target]\n",
    "\n",
    "num_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"Numeric columns:\", num_cols)\n",
    "print(\"Categorical columns:\", cat_cols)\n",
    "print(\"X shape, y shape:\", X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd273d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipelines\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "])\n",
    "print('Preprocessor ready.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9beb7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (stratify on y to keep class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78941aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train RandomForest pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "print(\"Training Random Forest (this can take a minute)...\")\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "print(\"Random Forest training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d83cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "y_pred = rf_pipeline.predict(X_test)\n",
    "y_proba = rf_pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "print(\"\\nROC AUC:\", auc)\n",
    "\n",
    "# Plot ROC curve\n",
    "RocCurveDisplay.from_estimator(rf_pipeline, X_test, y_test)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e3bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression baseline (faster)\n",
    "log_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', LogisticRegression(max_iter=2000))\n",
    "])\n",
    "print(\"Training Logistic Regression...\")\n",
    "log_pipeline.fit(X_train, y_train)\n",
    "y_pred_log = log_pipeline.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
    "print(classification_report(y_test, y_pred_log, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aeefe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances from RandomForest - need feature names from preprocessor\n",
    "ohe = rf_pipeline.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']\n",
    "ohe_features = list(ohe.get_feature_names_out(cat_cols))\n",
    "feature_names = num_cols + ohe_features\n",
    "importances = rf_pipeline.named_steps['clf'].feature_importances_\n",
    "feat_imp = pd.Series(importances, index=feature_names).sort_values(ascending=False).head(20)\n",
    "plt.figure(figsize=(8,6))\n",
    "feat_imp.plot(kind='barh')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title('Top 20 Feature Importances (RandomForest)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232df26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained RandomForest pipeline\n",
    "model_filename = 'bank_marketing_rf_pipeline.joblib'\n",
    "joblib.dump(rf_pipeline, model_filename)\n",
    "print(\"Saved trained pipeline to\", model_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf61051",
   "metadata": {},
   "source": [
    "### Notes & Next steps\n",
    "- If you plan to upload to GitHub, include:\n",
    "  - `Final_Classification_Project.ipynb`\n",
    "  - `bank_marketing_rf_pipeline.joblib` (optional, can be large)\n",
    "  - A small `README.md` describing how to run the notebook\n",
    "- If your internet environment blocks `wget` or `curl`, manually download `bank-full.csv` from UCI and upload into the notebook folder before running.\n",
    "- To reduce runtime, you can lower `n_estimators` in RandomForest or use a sample of the dataset for quick testing.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
